#!/usr/bin/env python3
"""Convert Andreas's Dictionary Data to Unicode."""

import collections
import enum
import pathlib
import re
import typing
from collections import abc

import bs4

from utils import file, lang, log

_SCRIPT_DIR: pathlib.Path = pathlib.Path(__file__).parent
_INPUT_DIR: pathlib.Path = _SCRIPT_DIR / "data" / "input"
_INPUT: list[pathlib.Path] = [
    _INPUT_DIR / "data_1.html",
    _INPUT_DIR / "data_2.html",
]
_OUTPUT: pathlib.Path = (
    _SCRIPT_DIR / "data" / "output" / "stmacariusmonastery_org.json"
)

_FONT_FAMILY_RE: re.Pattern[str] = re.compile(
    r"font-family:\s*([^;]+)",
    re.IGNORECASE,
)

_COPTIC_ENCODING: dict[str, str] = {
    # Capital letters.
    "A": "‚≤Ä",
    "B": "‚≤Ç",
    "G": "‚≤Ñ",
    "D": "‚≤Ü",
    "E": "‚≤à",
    "<": "‚≤ä",
    "Z": "‚≤å",
    "H": "‚≤é",
    "Q": "‚≤ê",
    "I": "‚≤í",
    "K": "‚≤î",
    "L": "‚≤ñ",
    "M": "‚≤ò",
    "N": "‚≤ö",
    "{": "‚≤ú",
    "O": "‚≤û",
    "P": "‚≤†",
    "R": "‚≤¢",
    "C": "‚≤§",
    "T": "‚≤¶",
    "U": "‚≤®",
    "V": "‚≤™",
    "X": "‚≤¨",
    "Y": "‚≤Æ",
    "W": "‚≤∞",
    "}": "œ¢",
    "F": "œ§",
    '"': "œ¶",
    "|": "œ®",
    "J": "œ™",
    "S": "œ¨",
    ":": "œÆ",
    # Small letters.
    "a": "‚≤Å",
    "b": "‚≤É",
    "g": "‚≤Ö",
    "d": "‚≤á",
    "e": "‚≤â",
    ",": "‚≤ã",
    "z": "‚≤ç",
    "h": "‚≤è",
    "q": "‚≤ë",
    "i": "‚≤ì",
    "k": "‚≤ï",
    "l": "‚≤ó",
    "m": "‚≤ô",
    "n": "‚≤õ",
    "[": "‚≤ù",
    "o": "‚≤ü",
    "p": "‚≤°",
    "r": "‚≤£",
    "c": "‚≤•",
    "t": "‚≤ß",
    "u": "‚≤©",
    "v": "‚≤´",
    "x": "‚≤≠",
    "y": "‚≤Ø",
    "w": "‚≤±",
    "]": "œ£",
    "f": "œ•",
    "'": "œß",
    "\\": "œ©",
    "j": "œ´",
    "s": "œ≠",
    ";": "œØ",
    # Symbols.
    "/": "\u0305",  # COMBINING OVERLINE
    "?": "\u0305",  # COMBINING OVERLINE
    "`": "`",  # TODO: (#452) Change to a combining grave accent.
    "~": "‚≥ø",  # TODO: (#452) Change to a combining grave accent.
    "%": ",",
    "ü†í": "‚Üí",
    "◊¥": "=",  # Mark of pronominal forms of verbs.
    ")": ")",
    "(": "(",
    "&": "?",
    ".": ".",
    "-": "-",
    "‚Äì": "-",
    " ": " ",
    "\u00a0": " ",  # Non-breaking space
    "‚Äô": "",  # Some characters don't translate to anything
    "‚Äò": "",
    "‚Äú": "",
    "‚Äù": "",
    "√¥": "",
}

_GREEK_ENCODING: dict[str, str] = {
    "¬•": "·ºÑ",
    "b": "Œ≤",
    "a": "Œ±",
    "q": "Œ∏",
    "r": "œÅ",
    "t": "œÑ",
    "o": "Œø",
    "j": "œÇ",
    "¬¢": "·ºÄ",
    "¬£": "Œ¨",
    "'": "·æø",
    "A": "Œë",
    "m": "Œº",
    "k": "Œ∫",
    "√ö": "œç",
    "O": "Œü",
    "d": "Œ¥",
    "‚Ä¶": "ŒØ",
    "u": "œÖ",
    "s": "œÉ",
    "w": "œâ",
    "n": "ŒΩ",
    "l": "Œª",
    "i": "Œπ",
    "c": "œá",
    "g": "Œ≥",
    "¬ª": "ŒÆ",
    "√í": "œå",
    "≈°": "Œ≠",
    "e": "Œµ",
    "‚Äπ": "·øñ",
    "h": "Œ∑",
    "p": "œÄ",
    "¬©": "·æ∂",
    ",": ",",
    " ": "",
    "¬°": "·ºÅ",
    "z": "Œ∂",
    "¬§": "·ºÖ",
    "√®": "œé",
    "√Æ": "·ø∂",
    "\n": "",
    "f": "œÜ",
    "¬Ø": "·æÖ",
    "√Å": "·øÜ",
    "√π": "·ø∑",
    "‚Äû": "·º∞",
    "‚Ä°": "·º¥",
    "‚Äî": "Œê",
    "y": "œà",
    "‚Ä†": "·ºµ",
    "∆í": "·º±",
    "x": "Œæ",
    "-": "-",
    "¬´": "·ºÜ",
    "√†": "·ø¶",
    "√ï": "·Ω∏",
    "‚Ñ¢": "·ºê",
    "`": "·øæ",
    "¬∂": "·æÜ",
    "√ú": "·Ωî",
    "√ô": "·Ωê",
    "G": "Œì",
    "\xa0": "",
    "(": "(",
    "D": "Œî",
    "v": "·æ≥",
    "Àú": "·ºë",
    "≈ì": "·ºî",
    "·º∂": "·º∂",
    "E": "Œï",
    "¬π": "·º°",
    "¬∫": "·º†",
    "‚Ä∫": "·ºï",
    "≈í": "·º∑",
    "ÀÜ": "·Ω∂",
    "√ò": "·Ωë",
    "√ê": "·ΩÅ",
    "‚àô": "·ø•",
    "√õ": "·Ωï",
    "√¢": "·Ωñ",
    "‚Äù": "·øé",
    "√ì": "·ΩÖ",
    "Z": "Œñ",
    "√Ä": "·º¢",
    ".": ".",
    "¬º": "·º•",
    "√É": "·º¶",
    "H": "Œó",
    "Q": "Œò",
    "I": "Œô",
    "\x8d": "",
    ")": ")",
    "Œµ": "Œµ",
    "œÑ": "œÑ",
    "Œ±": "Œ±",
    "=": "=",
    "¬¶": "·Ω∞",
    "Œê": "Œê",
    "K": "Œö",
    "œä": "œä",
    "L": "Œõ",
    "V": "·øÉ",
    "M": "Œú",
    "√£": "œã",
    "N": "Œù",
    "√ë": "·ΩÄ",
    "√ß": "·Ω†",
    "√î": "·ΩÑ",
    "√©": "·Ω•",
    "√¶": "·Ω°",
    "B": "Œí",
    "P": "Œ†",
    "R": "Œ°",
    "S": "Œ£",
    "T": "Œ§",
    "J": "·ø≥",
    "√°": "·Ωó",
    "F": "Œ¶",
    "¬¥": "·æ∑",
    "C": "Œß",
    "√≤": "·æ†",
    "√∞": "·Ω¶",
    "W": "Œ©",
    "¬Ω": "·º§",
    "√Ç": "·ºß",
    "√ç": "·øá",
}

_HEBREW_ENCODING: dict[str, str] = {
    # TODO: (#452) Fill this table
}

_UNKNOWN_ENCODING: dict[str, str] = {
    "◊¥": '"',
    "]": "]",
    "+": "+",
    "‚Üí": "‚Üí",
    "[": "[",
} | _GREEK_ENCODING


class Language(enum.Enum):
    COPTIC = "Coptic"
    GREEK = "Greek"
    ARABIC = "Arabic"
    HEBREW = "Hebrew"
    RIGHT_ARROW = "Right Arrow"
    UNKNOWN = "Unknown"


_LANG_ENCODING: dict[Language, dict[int, str]] = {
    Language.COPTIC: str.maketrans(_COPTIC_ENCODING),
    Language.GREEK: str.maketrans(_GREEK_ENCODING),
    Language.HEBREW: str.maketrans(_HEBREW_ENCODING),
    Language.UNKNOWN: str.maketrans(_UNKNOWN_ENCODING),
}


@typing.final
class Span:
    """Span represents a piece of text in the dictionary."""

    def __init__(self, content: str, language: Language):
        """Initialize a Span.

        Args:
            content: ASCII-encoded data.
            language: Text language, which will determine the encoding and
                conversion.
        """
        self.content: str = content
        self.language: Language = language


@typing.final
class DictionaryEntry:
    coptic: str = ""
    arabic: str = ""
    greek: str = ""
    hebrew: str = ""


def determine_language(text: str, style: str | None) -> Language:
    if any(map(lang.is_arabic_char, text)):
        return Language.ARABIC
    if not style:
        return Language.UNKNOWN

    # Extract font properties from inline styles
    font_match: re.Match[str] | None = _FONT_FAMILY_RE.search(style)

    if not font_match:
        return Language.GREEK

    font: str = font_match.group(1).strip().lower()
    if "athanasius" in font:
        return Language.COPTIC
    if "rhebrew" in font:
        return Language.HEBREW
    if "kenshrin1" in font:
        return Language.ARABIC
    if "wingdings" in font:
        return Language.RIGHT_ARROW
    if "greek" in font or "athena" in font:
        return Language.GREEK

    return Language.UNKNOWN


def parse_html_spans(file_path: pathlib.Path) -> list[Span]:
    """Read HTML file and extract span tags with their content and font
    information.

    Args:
        file_path: Path to the HTML file.

    Returns:
        list: List of dictionaries containing span content and font info.
    """

    soup: bs4.BeautifulSoup = bs4.BeautifulSoup(
        file.read(file_path),
        "html.parser",
    )

    results: list[Span] = []
    tag: bs4.Tag
    for tag in soup.find_all("span"):
        content: str = tag.get_text(strip=True).replace("\n", " ")

        if not content:
            continue

        style: str | list[str] | None = tag.get("style")
        assert style is None or isinstance(style, str)
        language: Language = determine_language(content, style)

        # Outer and inner spans cause some text to be repeated twice.
        if results and results[-1].content == content:
            # If the first occurrence of the text has no language, use the
            # second occurrence
            if results[-1].language == Language.UNKNOWN:
                results[-1].language = language
            continue

        results.append(Span(content, language))

    return results


# TODO: (#452) Once the Hebrew encoding is populated, this won't be needed
# anymore.
hebrew_freq: collections.Counter[str] = collections.Counter()


def convert_to_unicode(text: str, language: Language) -> str:
    if language == Language.RIGHT_ARROW:
        assert len(text) == 1
        return "‚Üí"

    if language == Language.ARABIC:
        # Arabic is not encoded.
        return text

    # TODO: (#452) Stop giving Hebrew special treatment.
    if language == Language.HEBREW:
        # We don't have the Hebrew encoding yet.
        # Add text to the Hebrew letter frequency tracker.
        hebrew_freq.update(text)
        # In the original text, Hebrew is written in reverse.
        return text[::-1]

    # This is an encoded language.
    return text.translate(_LANG_ENCODING[language])


def squash(dictionary: list[Span]) -> list[Span]:
    """Merge consecutive strings with the same language (or if either of them
    is unknown).

    Args:
        dictionary: A list of Span objects containing text content and language
                    information.

    Returns:
        A list of Span objects with consecutive spans merged based on language
        compatibility.
    """

    result: list[Span] = []
    for span in dictionary:
        if result and span.language in [Language.UNKNOWN, result[-1].language]:
            result[-1].content += span.content
            continue
        result.append(span)

    return result


def remove_extra_whitespace(text: str) -> str:
    return " ".join(text.split())


def get_next_letter(letter: str) -> str:
    return chr(ord(letter) + 2)


def get_capital_letter(letter: str) -> str:
    code: int = ord(letter)
    assert code % 2
    return chr(code - 1)


def make_section_name(letter: str) -> str:
    return f"{get_capital_letter(letter)},{letter}"


def make_dictionary(spans: list[Span]) -> abc.Generator[DictionaryEntry]:
    """This method merges entries in the original dictionary to form the new
    dictionary.

    Subsequent entries are merged based on language such that it must
    start in Coptic, and end in Arabic.

    Args:
        spans: A list of Span objects containing text content and language
            information.

    Yields:
        DictionaryEntry objects with merged content grouped by entries.
    """
    # used to remove a prefix later on
    letter: str = "‚≤Å"
    section_name: str = make_section_name(letter)

    entry: DictionaryEntry = DictionaryEntry()
    for i in range(len(spans)):
        spans[i].content += " "
        match spans[i].language:
            case Language.COPTIC:
                entry.coptic += spans[i].content
            case Language.ARABIC:
                entry.arabic += spans[i].content
            case Language.RIGHT_ARROW:
                entry.coptic += spans[i].content
            case Language.GREEK:
                entry.greek += spans[i].content
            case Language.HEBREW:
                entry.hebrew += spans[i].content

        entry_language: Language = spans[i].language
        next_entry_language: Language | None = (
            spans[i + 1].language if i < len(spans) - 1 else None
        )

        if entry_language == Language.ARABIC and next_entry_language in [
            Language.COPTIC,
            None,
        ]:
            # First entry in every section has an extra pair of the letter
            if entry.coptic.startswith(section_name):
                entry.coptic = entry.coptic.removeprefix(section_name)
                letter = get_next_letter(letter)
                section_name = make_section_name(letter)
            yield entry
            entry = DictionaryEntry()


def main() -> None:
    data: list[Span] = []
    for input_file in _INPUT:
        for span in parse_html_spans(input_file):
            span.content = remove_extra_whitespace(
                convert_to_unicode(span.content, span.language),
            )
            data.append(span)

    data = squash(data)
    dictionary = make_dictionary(data)

    file.write(
        file.json_dumps([obj.__dict__ for obj in dictionary]),
        _OUTPUT,
    )

    log.info("Unknown Hebrew characters:", len(hebrew_freq))
    for char, count in hebrew_freq.most_common():
        log.info(f"{char}\t", count, level=False)


if __name__ == "__main__":
    main()
